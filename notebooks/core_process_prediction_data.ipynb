{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Workflow: Get NAIP imageries from given addresses\n",
    "Purpose: The two primary prediction study area are Los Angeles county and Kansas City. For LA, the official building footprint data from LA city government are used to get the geometry of the rooftops. For Kansas City, the rooftop geometries are acquired from Microsoft footprint data. The geometries are then used to acquire NAIP imagery for all the roofs within the AOI. The mean band values (R, G, B, NIR) for each rooftop are saved and used for subsequent operation. \n",
    "<br>\n",
    "*Date: 2019-10-31*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import itertools\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "#\n",
    "import numpy as np\n",
    "import shapely\n",
    "from shapely.geometry import shape, Point\n",
    "from shapely.geometry import mapping, Polygon\n",
    "# import cartopy\n",
    "import geojson\n",
    "import fiona\n",
    "import gdal\n",
    "import h5py\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "# import ogr, gdal\n",
    "from glob import glob\n",
    "\n",
    "import requests\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import collections\n",
    "\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "from numpy import mean\n",
    "\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "import descarteslabs as dl\n",
    "from descarteslabs.vectors import FeatureCollection\n",
    "\n",
    "print (sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the AOI for processing (LA for Los Angeles or KC for Kansas City)\n",
    "prediction_city = 'LA'\n",
    "\n",
    "# set the year to process \n",
    "prediction_year = 2009\n",
    "\n",
    "# range of date to search for imagery\n",
    "start_date = '2009-01-01'\n",
    "end_date = '2009-12-01'\n",
    "\n",
    "# resolution of the downloaded imagery\n",
    "resolution = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from multiprocessing import Process, cpu_count\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#\n",
    "# CONFIG\n",
    "#\n",
    "MAX_POOL_PROCESSES=cpu_count()-1\n",
    "MAX_THREADPOOL_PROCESSES=16\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# METHODS\n",
    "#\n",
    "\"\"\" MAP METHODS\n",
    "  Args:\n",
    "    * map_function <function>: \n",
    "      a function to map over args list. the function should take a single argument.\n",
    "      if multiple arguments are needed accept them as a single list or tuple\n",
    "    * args_list <list>: the list of arguments to map over\n",
    "    * max_process <int>: number of processes\n",
    "      - for max_with_pool defaults to the number of cpus minus 1\n",
    "      - for max_with_threadpool defaults to 16\n",
    "      - map_sequential ignores this argument as its doesn't actually do \n",
    "        any multiprocesssing \n",
    "  Return:\n",
    "    List of return values from map_function\n",
    "  Notes:\n",
    "    map_sequential does NOT multiprocess.  it can be used as a sequential drop-in \n",
    "    replacement for map_with_pool/threadpool.  this is useful for:\n",
    "      - development \n",
    "      - debugging\n",
    "      - benchmarking \n",
    "\"\"\"\n",
    "def map_with_pool(map_function,args_list,max_processes=MAX_POOL_PROCESSES):\n",
    "  pool=Pool(processes=min(len(args_list),max_processes))\n",
    "  return _run_pool(pool,map_function,args_list)\n",
    "\n",
    "\n",
    "def map_with_threadpool(map_function,args_list,max_processes=MAX_THREADPOOL_PROCESSES):\n",
    "  pool=ThreadPool(processes=min(len(args_list),max_processes))\n",
    "  return _run_pool(pool,map_function,args_list)\n",
    "\n",
    "\n",
    "def map_sequential(map_function,args_list,print_args=False,noisy=False,**dummy_kwargs):\n",
    "  if noisy:\n",
    "    print('multiprocessing(test):')\n",
    "  out=[]\n",
    "  for i,args in enumerate(args_list):\n",
    "      if noisy: \n",
    "        print('\\t{}...'.format(i))\n",
    "      if print_args:\n",
    "        print('\\t{}'.format(args))\n",
    "      out.append(map_function(args))\n",
    "  if noisy: \n",
    "    print('-'*25)\n",
    "  return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" simple: vanilla multiprocessing\n",
    "  Args:\n",
    "    * function <function>: function. function can take multiple arguments \n",
    "    * args_list <list>: the list of argument lists\n",
    "    * join <bool[True]>: join processes before return\n",
    "  Return: \n",
    "    List of processes \n",
    "\"\"\"\n",
    "def simple(function,args_list,join=True):\n",
    "  procs=[]\n",
    "  for args in args_list:\n",
    "      proc=Process(\n",
    "          target=function, \n",
    "          args=args)\n",
    "      procs.append(proc)\n",
    "      proc.start()\n",
    "  if join:\n",
    "    for proc in procs:\n",
    "        proc.join()\n",
    "  return procs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" MPList\n",
    "Run the above methods on map_function,args_list pairs where the map_function\n",
    "changes for each new set of args in args_list\n",
    "Args:\n",
    "    pool_type<str>: \n",
    "        one of MPList.POOL|THREAD|SEQUENTIAL.  determines which map_function \n",
    "        and default max_processes to use. If not MPList.THREAD|SEQUENTIAL it \n",
    "        will default to MPList.POOL.\n",
    "    max_processes<int>:\n",
    "        if not passed will set default based on pool_type\n",
    "    jobs<list>:\n",
    "        list of (target,args,kwargs) tuples. Note: use the append method rather than\n",
    "        creating (target,args,kwargs) tuples\n",
    "        \n",
    "\"\"\"\n",
    "class MPList():\n",
    "    #\n",
    "    # POOL TYPES\n",
    "    #\n",
    "    POOL='pool'\n",
    "    THREAD='threading'\n",
    "    SEQUENTIAL='sequential'\n",
    "    \n",
    "\n",
    "    #\n",
    "    # PUBLIC\n",
    "    #\n",
    "    def __init__(self,pool_type=None,max_processes=None,jobs=None):\n",
    "        self.pool_type=pool_type or self.POOL\n",
    "        self.max_processes=max_processes\n",
    "        self.jobs=jobs or []\n",
    "\n",
    "        \n",
    "    def append(self,target,*args,**kwargs):\n",
    "        self.jobs.append((target,)+(args,)+(kwargs,))\n",
    "        \n",
    "    \n",
    "    def run(self):\n",
    "        self.start_time=datetime.now()\n",
    "        map_func,self.max_processes=self._map_func_max_processes()\n",
    "        out=map_func(self._target,self.jobs,max_processes=self.max_processes)\n",
    "        self.end_time=datetime.now()\n",
    "        self.duration=str(self.end_time-self.start_time)\n",
    "        return out\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.jobs)\n",
    "    \n",
    "    \n",
    "    #\n",
    "    # INTERNAL\n",
    "    #    \n",
    "    def _map_func_max_processes(self):\n",
    "        if self.pool_type==MPList.THREAD:\n",
    "            map_func=map_with_threadpool\n",
    "            max_processes=self.max_processes or MAX_THREADPOOL_PROCESSES\n",
    "        elif self.pool_type==MPList.SEQUENTIAL:\n",
    "            map_func=map_sequential\n",
    "            max_processes=False\n",
    "        else:\n",
    "            map_func=map_with_pool\n",
    "            max_processes=self.max_processes or MAX_POOL_PROCESSES\n",
    "        return map_func, max_processes\n",
    "        \n",
    "        \n",
    "    def _target(self,args):\n",
    "        target,args,kwargs=args\n",
    "        return target(*args,**kwargs)\n",
    "        \n",
    "    \n",
    "\n",
    "#\n",
    "# INTERNAL METHODS\n",
    "#\n",
    "def _stop_pool(pool,success=True):\n",
    "  pool.close()\n",
    "  pool.join()\n",
    "  return success\n",
    "\n",
    "\n",
    "def _map_async(pool,map_func,objects):\n",
    "  try:\n",
    "    return pool.map_async(map_func,objects)\n",
    "  except KeyboardInterrupt:\n",
    "    print(\"Caught KeyboardInterrupt, terminating workers\")\n",
    "    pool.terminate()\n",
    "    return False\n",
    "  else:\n",
    "    print(\"Failure\")\n",
    "    return _stop_pool(pool,False)\n",
    "\n",
    "\n",
    "def _run_pool(pool,map_function,args_list):\n",
    "  out=_map_async(pool,map_function,args_list)\n",
    "  _stop_pool(pool)\n",
    "  return out.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_dict_decorator(func):\n",
    "    def decorator(arg_dict):\n",
    "        return func(**arg_dict)\n",
    "    return decorator\n",
    "\n",
    "\n",
    "@arg_dict_decorator\n",
    "def calc_bands_LA_2012(type,properties,geometry):    \n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < 2:\n",
    "        try:\n",
    "            cnt = properties['cnt']\n",
    "            polygon = shape(geometry)\n",
    "            bld_id = properties['BLD_ID']\n",
    "            shp_area = properties['Shape_Area']\n",
    "            \n",
    "            # search for scenes from Descartes lab platform\n",
    "            scenes, ctx = dl.scenes.search(geometry, products=product, start_datetime=start_date, \n",
    "                                           end_datetime=end_date, limit=None)\n",
    "\n",
    "            rf_no = cnt\n",
    "\n",
    "            img_id = - 1    \n",
    "\n",
    "            for scene in scenes:\n",
    "\n",
    "                img_id = img_id + 1\n",
    "                \n",
    "                # save the band values as arrays\n",
    "                naip_data = scene.ndarray(bands=\"red green blue nir\", ctx=ctx.assign(resolution=resolution),mask_alpha=False)\n",
    "                red = naip_data[0]\n",
    "                red = red.astype(float)\n",
    "\n",
    "                green = naip_data[1]\n",
    "                green = green.astype(float)\n",
    "\n",
    "                blue = naip_data[2]\n",
    "                blue = blue.astype(float)\n",
    "                \n",
    "                nir = naip_data[3]\n",
    "                nir = nir.astype(float)\n",
    "                        \n",
    "                arr = [red,green,blue,nir]\n",
    "\n",
    "                flat_arr = []\n",
    "                # flattened array of tuples\n",
    "                flat_list = zip(*map(lambda x:x.flatten(),arr))\n",
    "                for i in flat_list:\n",
    "                    flat_arr.append(i)   \n",
    "                    \n",
    "                selected_pixels=[]\n",
    "                # remove blank pixels \n",
    "                for pixels in flat_arr:\n",
    "                    if pixels[0] != 0 or pixels[1] != 0 or pixels[2] != 0 or pixels[3] != 0:\n",
    "                        selected_pixels.append(pixels)\n",
    "                        \n",
    "                # raw band values        \n",
    "                raw_red_b = []\n",
    "                raw_green_b = []\n",
    "                raw_blue_b = []\n",
    "                raw_nir_b = []\n",
    "\n",
    "                for pixels in selected_pixels:\n",
    "                    raw_red_b.append(pixels[0]) \n",
    "                    raw_green_b.append(pixels[1])\n",
    "                    raw_blue_b.append(pixels[2])\n",
    "                    raw_nir_b.append(pixels[3])\n",
    "                    \n",
    "                # calculate the raw mean values for all the bands from this list\n",
    "                raw_red_mean=mean(raw_red_b)\n",
    "                raw_green_mean=mean(raw_green_b)\n",
    "                raw_blue_mean=mean(raw_blue_b)\n",
    "                raw_nir_mean=mean(raw_nir_b)\n",
    "\n",
    "                total_pixel = len(selected_pixels) # calculate the number of pixels within the roof used for calculation               \n",
    "\n",
    "                imgs.append(img_id)\n",
    "                roofs.append(rf_no)\n",
    "                footprint_shapes.append(polygon)\n",
    "\n",
    "                total_pixels.append(total_pixel)            \n",
    "\n",
    "                raw_reds.append(raw_red_mean)\n",
    "                raw_greens.append(raw_green_mean)\n",
    "                raw_blues.append(raw_blue_mean)\n",
    "                raw_nirs.append(raw_nir_mean)\n",
    "                \n",
    "                bld_ids.append(bld_id)\n",
    "                shp_areas.append(shp_area)\n",
    "\n",
    "            break\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            if attempts == 2:\n",
    "                print('unsuccessfull at count', cnt)\n",
    "                unsuc_cnts.append(cnt)\n",
    "            else:\n",
    "                time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_dict_decorator(func):\n",
    "    def decorator(arg_dict):\n",
    "        return func(**arg_dict)\n",
    "    return decorator\n",
    "\n",
    "\n",
    "@arg_dict_decorator\n",
    "def calc_bands_LA_2014(type,properties,geometry):    \n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < 2:\n",
    "        try:\n",
    "            cnt = properties['cnt']\n",
    "            polygon = shape(geometry)\n",
    "            \n",
    "            if properties['OLD_BLD_ID'] == None:\n",
    "                bld_id = properties['BLD_ID']\n",
    "            else:\n",
    "                bld_id = properties['OLD_BLD_ID']\n",
    "                \n",
    "            status = properties['STATUS']\n",
    "            use_type = properties['UseType']\n",
    "            \n",
    "            shp_area = properties['Shape_Ar_1']\n",
    "\n",
    "            scenes, ctx = dl.scenes.search(geometry, products=product, start_datetime=start_date, \n",
    "                                           end_datetime=end_date, limit=None)\n",
    "\n",
    "            rf_no = cnt\n",
    "\n",
    "            img_id = - 1    \n",
    "\n",
    "            for scene in scenes:\n",
    "\n",
    "                img_id = img_id + 1\n",
    "\n",
    "                naip_data = scene.ndarray(bands=\"red green blue nir\", ctx=ctx.assign(resolution=resolution),mask_alpha=False)\n",
    "                red = naip_data[0]\n",
    "                red = red.astype(float)\n",
    "\n",
    "                green = naip_data[1]\n",
    "                green = green.astype(float)\n",
    "\n",
    "                blue = naip_data[2]\n",
    "                blue = blue.astype(float)\n",
    "                \n",
    "                nir = naip_data[3]\n",
    "                nir = nir.astype(float)\n",
    "                        \n",
    "                arr = [red,green,blue,nir]\n",
    "\n",
    "                flat_arr = []\n",
    "                # flattened array of tuples\n",
    "                flat_list = zip(*map(lambda x:x.flatten(),arr))\n",
    "                for i in flat_list:\n",
    "                    flat_arr.append(i)   \n",
    "                    \n",
    "                selected_pixels=[]\n",
    "                # remove blank pixels \n",
    "                for pixels in flat_arr:\n",
    "                    if pixels[0] != 0 or pixels[1] != 0 or pixels[2] != 0 or pixels[3] != 0:\n",
    "                        selected_pixels.append(pixels)\n",
    "                        \n",
    "                # raw band values        \n",
    "                raw_red_b = []\n",
    "                raw_green_b = []\n",
    "                raw_blue_b = []\n",
    "                raw_nir_b = []\n",
    "\n",
    "                for pixels in selected_pixels:\n",
    "                    raw_red_b.append(pixels[0]) \n",
    "                    raw_green_b.append(pixels[1])\n",
    "                    raw_blue_b.append(pixels[2])\n",
    "                    raw_nir_b.append(pixels[3])\n",
    "                    \n",
    "                # calculate the raw mean values for all the bands from this list\n",
    "                raw_red_mean=mean(raw_red_b)\n",
    "                raw_green_mean=mean(raw_green_b)\n",
    "                raw_blue_mean=mean(raw_blue_b)\n",
    "                raw_nir_mean=mean(raw_nir_b)\n",
    "\n",
    "                total_pixel = len(selected_pixels) # calculate the number of pixels within the roof used for calculation               \n",
    "\n",
    "                imgs.append(img_id)\n",
    "                roofs.append(rf_no)\n",
    "                footprint_shapes.append(polygon)\n",
    "\n",
    "                total_pixels.append(total_pixel)             \n",
    "\n",
    "                raw_reds.append(raw_red_mean)\n",
    "                raw_greens.append(raw_green_mean)\n",
    "                raw_blues.append(raw_blue_mean)\n",
    "                raw_nirs.append(raw_nir_mean)\n",
    "                \n",
    "                bld_ids.append(bld_id)\n",
    "                shp_areas.append(shp_area)\n",
    "                statuss.append(status)\n",
    "                use_types.append(use_type)\n",
    "\n",
    "            break\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            if attempts == 2:\n",
    "                print('unsuccessfull at count', cnt)\n",
    "                unsuc_cnts.append(cnt)\n",
    "            else:\n",
    "                time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_dict_decorator(func):\n",
    "    def decorator(arg_dict):\n",
    "        return func(**arg_dict)\n",
    "    return decorator\n",
    "\n",
    "\n",
    "@arg_dict_decorator\n",
    "def calc_bands_KC(type,properties,geometry):    \n",
    "    attempts = 0\n",
    "\n",
    "    while attempts < 2:\n",
    "        cnt = (properties['cnt'])\n",
    "        rf_no = cnt\n",
    "        img_id = - 1\n",
    "\n",
    "        try:\n",
    "            polygon = shape(geometry)\n",
    "\n",
    "            scenes, ctx = dl.scenes.search(geometry, products=product, start_datetime=start_date, \n",
    "                                           end_datetime=end_date, limit=None)                            \n",
    "\n",
    "            for scene in scenes:\n",
    "\n",
    "                # find the state that the imagery belong to\n",
    "                state = scene.properties.directory\n",
    "                state = state[0:2]\n",
    "\n",
    "                img_id = img_id + 1\n",
    "\n",
    "                naip_data = scene.ndarray(bands=\"red green blue nir\", ctx=ctx.assign(resolution=1),mask_alpha=False)\n",
    "                red = naip_data[0]\n",
    "                red = red.astype(float)\n",
    "\n",
    "                green = naip_data[1]\n",
    "                green = green.astype(float)\n",
    "\n",
    "                blue = naip_data[2]\n",
    "                blue = blue.astype(float)\n",
    "\n",
    "                nir = naip_data[3]\n",
    "                nir = nir.astype(float)\n",
    "\n",
    "                arr = [red,green,blue,nir]\n",
    "\n",
    "                flat_arr = []\n",
    "                # flattened array of tuples\n",
    "                flat_list = zip(*map(lambda x:x.flatten(),arr))\n",
    "                for i in flat_list:\n",
    "                    flat_arr.append(i)   \n",
    "\n",
    "                selected_pixels=[]\n",
    "                # remove blank pixels and normalize for scenes\n",
    "                for pixels in flat_arr:\n",
    "                    if pixels[0] != 0 or pixels[1] != 0 or pixels[2] != 0 or pixels[3] != 0:\n",
    "                        selected_pixels.append(pixels)\n",
    "\n",
    "                # raw band values        \n",
    "                raw_red_b = []\n",
    "                raw_green_b = []\n",
    "                raw_blue_b = []\n",
    "                raw_nir_b = []\n",
    "\n",
    "                for pixels in selected_pixels:\n",
    "                    raw_red_b.append(pixels[0]) \n",
    "                    raw_green_b.append(pixels[1])\n",
    "                    raw_blue_b.append(pixels[2])\n",
    "                    raw_nir_b.append(pixels[3])\n",
    "\n",
    "                # calculate the mean values for all the bands from this list\n",
    "                raw_red_mean=mean(raw_red_b)\n",
    "                raw_green_mean=mean(raw_green_b)\n",
    "                raw_blue_mean=mean(raw_blue_b)\n",
    "                raw_nir_mean=mean(raw_nir_b)\n",
    "\n",
    "                total_pixel = len(selected_pixels) # calculate the size of the roof               \n",
    "\n",
    "                imgs.append(img_id)\n",
    "                roofs.append(rf_no)\n",
    "                footprint_shapes.append(polygon)\n",
    "\n",
    "                total_pixels.append(total_pixel)              \n",
    "\n",
    "                raw_reds.append(raw_red_mean)\n",
    "                raw_greens.append(raw_green_mean)\n",
    "                raw_blues.append(raw_blue_mean)\n",
    "                raw_nirs.append(raw_nir_mean)\n",
    "\n",
    "                states.append(state)\n",
    "\n",
    "\n",
    "            break\n",
    "        except Exception as e:\n",
    "            attempts += 1\n",
    "            if attempts == 2:\n",
    "                print('unsuccessfull at count', cnt)\n",
    "                unsuc_cnts.append(rf_no)\n",
    "            else:\n",
    "                time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the current footprint source based on prediction year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prediction_city == 'LA':\n",
    "    if prediction_year <= 2012:\n",
    "        with open('/data/phase_i/official_footprints/LA_county_official_footprints_2014.geojson') as f:\n",
    "            js = json.load(f)\n",
    "    else:\n",
    "        with open('/data/phase_i/official_footprints/LA_county_official_footprints_2009.geojson') as f:\n",
    "            js = json.load(f)\n",
    "elif prediction_city == 'KC':\n",
    "    with open('/data/phase_i/microsoft_footprints/kansas_city_MS_building_footprints.geojson') as f:\n",
    "        js = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_list = js['features']\n",
    "\n",
    "print(len(arg_list))\n",
    "\n",
    "cnt = -1\n",
    "\n",
    "# Add a unique id to each roofs\n",
    "for feat in arg_list:\n",
    "    cnt = cnt + 1\n",
    "    feat['properties']['cnt'] = cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the main function to process the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product = u'usda:naip:rgbn:v1'\n",
    "\n",
    "roofs = []\n",
    "imgs = []\n",
    "footprint_shapes=[]\n",
    "total_pixels = []\n",
    "\n",
    "raw_reds = []\n",
    "raw_greens = []\n",
    "raw_blues = []\n",
    "raw_nirs = []\n",
    "\n",
    "unsuc_cnts = []\n",
    "\n",
    "bld_ids = []\n",
    "shp_areas = []\n",
    "statuss = []\n",
    "use_types = []\n",
    "\n",
    "states = []\n",
    "\n",
    "if prediction_city == 'LA':\n",
    "    if prediction_year <= 2012:\n",
    "        %time out = map_with_threadpool(calc_bands_LA_2012,arg_list,max_processes=32)\n",
    "    else:     \n",
    "        %time out = map_with_threadpool(calc_bands_LA_2014,arg_list,max_processes=32)\n",
    "\n",
    "elif prediction_city == 'KC':\n",
    "    %time out = map_with_threadpool(calc_bands_KC,arg_list,max_processes=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finished multiprocessing')\n",
    "\n",
    "print('unsuccessfull counts = ', len(unsuc_cnts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the results to a pandas library and then save to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prediction_city == 'LA':\n",
    "    if prediction_year <= 2012:\n",
    "        # store the results to a pandas library.\n",
    "        df = pd.DataFrame({ 'roof_no': roofs, 'img_id':imgs, 'footprint_shapes':footprint_shapes,'total_pixels': total_pixels,\n",
    "                           'bld_id':bld_ids, 'shp_area':shp_areas, 'status':statuss, 'use_type':use_types,\n",
    "                          'raw_red_mean':raw_reds,'raw_green_mean': raw_greens,'raw_blue_mean': raw_blues,'raw_nir_mean': raw_nirs})\n",
    "        # Write the full results to csv using the pandas library. \n",
    "        df.to_csv('band_values_NAIP_LA_'+prediction_year+'.csv',encoding='utf8')\n",
    "    else:\n",
    "        # store the results to a pandas library.\n",
    "        df = pd.DataFrame({ 'roof_no': roofs, 'img_id':imgs, 'footprint_shapes':footprint_shapes,'total_pixels': total_pixels,\n",
    "                           'bld_id':bld_ids, 'shp_area':shp_areas,\n",
    "                    'raw_red_mean':raw_reds,'raw_green_mean': raw_greens,'raw_blue_mean': raw_blues,'raw_nir_mean': raw_nirs})\n",
    "\n",
    "        # Write the full results to csv using the pandas library. \n",
    "        df.to_csv('band_values_NAIP_LA_'+prediction_year+'.csv',encoding='utf8')\n",
    "\n",
    "elif prediction_city == 'KC':\n",
    "    # store the results to a pandas library.\n",
    "    df = pd.DataFrame({ 'roof_no': roofs, 'img_id':imgs, 'footprint_shapes':footprint_shapes,'total_pixels': total_pixels,\n",
    "                       'state': states,\n",
    "                      'raw_red_mean':raw_reds,'raw_green_mean': raw_greens,'raw_blue_mean': raw_blues,'raw_nir_mean': raw_nirs})\n",
    "\n",
    "    # Write the full results to csv using the pandas library. \n",
    "    df.to_csv('band_values_NAIP_KC_'+prediction_year+'.csv',encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
