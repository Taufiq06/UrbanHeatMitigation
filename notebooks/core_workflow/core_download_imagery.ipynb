{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Workflow: Download NAIP imagery for training data\n",
    "Purpose: Specify the desired satellite imagery—from where, from when, including what spectral bands—and store it locally as multi-band, geospatial raster files. \n",
    "<br>\n",
    "*Date: 10-31-2019*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/opt/caffe/python', '/opt/caffe2/build', '/data/home/peter/notebooks/urban_heat', '/anaconda/envs/py36/lib/python36.zip', '/anaconda/envs/py36/lib/python3.6', '/anaconda/envs/py36/lib/python3.6/lib-dynload', '/anaconda/envs/py36/lib/python3.6/site-packages', '/anaconda/envs/py36/lib/python3.6/site-packages/IPython/extensions', '/data/home/peter/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import itertools\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "#\n",
    "import numpy as np\n",
    "import shapely\n",
    "from shapely.geometry import shape, Point\n",
    "from shapely.geometry import mapping, Polygon\n",
    "# import cartopy\n",
    "import geojson\n",
    "import fiona\n",
    "import h5py\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gdal\n",
    "from glob import glob\n",
    "\n",
    "import jenkspy\n",
    "\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import collections\n",
    "from numpy import mean\n",
    "\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "import time\n",
    "\n",
    "import descarteslabs as dl\n",
    "print (sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shape(place_shapefile):\n",
    "    c = fiona.open(place_shapefile)\n",
    "    pol = c.next()\n",
    "    shape = {}\n",
    "    shape['type'] = pol['type']\n",
    "    shape['properties'] = pol['properties']\n",
    "    shape['geometry'] = {}\n",
    "    shape['geometry']['type'] = 'Polygon'  # pol['geometry']['type']\n",
    "    shape['geometry']['coordinates'] = [[]]\n",
    "    # if MultiPolygon (e.g., city='kampala')\n",
    "    if (len(pol['geometry']['coordinates'])>1):\n",
    "        # identify largest single polygon\n",
    "#         print (\"MultiPolygon\", len(pol['geometry']['coordinates']))\n",
    "        p_argmax = 0 \n",
    "        pn_max = 0\n",
    "        for p in range(len(pol['geometry']['coordinates'])):\n",
    "            pn = len(pol['geometry']['coordinates'][p][0])\n",
    "            if pn>pn_max:\n",
    "                p_argmax = p\n",
    "                pn_max = pn\n",
    "#             print (p, pn, p_argmax, pn_max )\n",
    "        # make largest polygon the only polygon, move other polys to a backup variable \n",
    "        polygon = pol['geometry']['coordinates'][p_argmax]\n",
    "        \n",
    "        xmin =  180\n",
    "        xmax = -180\n",
    "        ymin =  90\n",
    "        ymax = -90\n",
    "        for x,y in polygon:\n",
    "            xmin = xmin if xmin < x else x\n",
    "            xmax = xmax if xmax > x else x\n",
    "            ymin = ymin if ymin < y else y\n",
    "            ymax = ymax if ymax > y else y\n",
    "            shape['geometry']['coordinates'][0].append([x,y])\n",
    "        shape['bbox'] = [xmin,ymin,xmax,ymax]\n",
    "\n",
    "        return shape\n",
    "    else:\n",
    "#         print ('simple polygon')\n",
    "        polygon = pol['geometry']['coordinates']\n",
    "       \n",
    "        xmin =  180\n",
    "        xmax = -180\n",
    "        ymin =  90\n",
    "        ymax = -90\n",
    "        for x,y in polygon[0]:\n",
    "            xmin = xmin if xmin < x else x\n",
    "            xmax = xmax if xmax > x else x\n",
    "            ymin = ymin if ymin < y else y\n",
    "            ymax = ymax if ymax > y else y\n",
    "            shape['geometry']['coordinates'][0].append([x,y])\n",
    "        shape['bbox'] = [xmin,ymin,xmax,ymax]\n",
    "    \n",
    "    return shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root='/data/phase_i/'\n",
    "\n",
    "bands=['red','green','blue','nir']; suffix='RGBNA'  # S2, Lx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the imageries for the saved footprints from DL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your input file here\n",
    "input_filename = \"footprints_data.csv\"\n",
    "\n",
    "# Read the data to a Pandas Dataframe\n",
    "df_2 = pd.read_csv(input_filename, encoding='utf8')\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses= df_2[['roof_add','footprint_path','footprint_shapes','longitude','latitude','start_date','end_date','Solar-Initial']].apply(tuple, axis=1)\n",
    "addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path for download imageries\n",
    "data_path='/data/phase_i/roof_img/george/naip_v1/'\n",
    "\n",
    "roof_id = -1\n",
    "\n",
    "img_path = []\n",
    "footprint_shapes = []\n",
    "lats = []\n",
    "lons=[]\n",
    "exp_alb = []\n",
    "tile_id = []\n",
    "roof_add = []\n",
    "\n",
    "# for shapefiles in paths:\n",
    "for Y, X in addresses.iteritems():\n",
    "    shapefiles = str(X[1])\n",
    "    lati = str(X[4])\n",
    "    lat=lati[0:7]\n",
    "    lon = str(X[3])\n",
    "    start_date = str(X[5])\n",
    "    end_date = str(X[6])\n",
    "    albedo = X[7]\n",
    "    rf_ad = X[0]\n",
    "    ft_shp = X[2]\n",
    "    \n",
    "    \n",
    "    shape = load_shape(shapefiles)\n",
    "\n",
    "    print ('searching imageries for'+shapefiles)\n",
    "    \n",
    "    product = u'usda:naip:rgbn:v1'\n",
    "\n",
    "    #  Search metadata given a spatio-temporal query\n",
    "    feature_collection = dl.metadata.search(products=[product], start_datetime=start_date, end_datetime=end_date,\n",
    "                                             fields=['acquired'], sort_field='acquired',sort_order='asc',geom=shape['geometry'])\n",
    "    \n",
    "    naip_ids = [f['id'] for f in feature_collection['features']]\n",
    "    naip_ids.sort()\n",
    "    print (len(naip_ids), naip_ids)\n",
    "    \n",
    "    \n",
    "    if len(naip_ids) != 0:\n",
    "        roof_id = roof_id+1\n",
    "        naip_dates = [f['properties'] for f in feature_collection['features']]\n",
    "#     print (naip_dates)\n",
    "        naip_dates = naip_dates[0]\n",
    "    \n",
    "    continue_index = 0\n",
    "    \n",
    "    img_id = - 1\n",
    "    \n",
    "    for imageries in naip_ids:        \n",
    "        print ('downloading '+imageries)\n",
    "        ids = imageries[18:49]\n",
    "#         print(ids)\n",
    "        continue_index = 0\n",
    "        img_id = img_id + 1\n",
    "        naip_band_file =  data_path+str(imageries[-6:-4])+'_naipV1_'+str(naip_dates)+'_roof_'+str(roof_id).zfill(5)+'_'+'img_'+str(img_id).zfill(2)+'_'+str(resolution)+'m'\n",
    "#         print (naip_band_file)\n",
    "        date = naip_band_file[65:75]\n",
    "#         print (date)\n",
    "        naip_band_file =  data_path+'naipV1_'+date+'_rf_'+str(roof_id).zfill(5)+'_'+'img_'+str(img_id).zfill(2)+'_lat_'+lat+'_'+str(resolution)+'m'\n",
    "#         print (naip_band_file)\n",
    "        naip = dl.raster.raster(\n",
    "                imageries,\n",
    "                bands=bands,\n",
    "                data_type='UInt16',\n",
    "                cutline=shape['geometry'],\n",
    "                save=True,\n",
    "                outfile_basename=naip_band_file)\n",
    "        pt = str(naip_band_file)+'.tif'\n",
    "        print(pt)\n",
    "        img_path.append(pt)\n",
    "        lats.append(lati)\n",
    "        lons.append(lon)\n",
    "        exp_alb.append(albedo)\n",
    "        tile_id.append(ids)\n",
    "        roof_add.append(rf_ad)\n",
    "        footprint_shapes.append(ft_shp)\n",
    "\n",
    "# store the results to a pandas library.\n",
    "df_path = pd.DataFrame({'roof_address':roof_add, 'img_path': img_path, 'footprint_shapes':footprint_shapes, 'tile_id': tile_id, \n",
    "                        'latitude': lats,'longitude': lons, 'expected_albedo': exp_alb})\n",
    "\n",
    "# Write the full results to csv using the pandas library. \n",
    "df_path.to_csv('path_imagery.csv',encoding='utf8')\n",
    "        \n",
    "print('largest roof id: ',roof_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
