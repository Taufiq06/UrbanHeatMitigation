{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Workflow: Get NAIP imageries from street shapefiles\n",
    "Purpose: Specify the desired satellite imagery—from where, from when, including what spectral bands—and store it locally as multi-band, geospatial raster files. \n",
    "<br>\n",
    "*Date: 2019-02-08*\n",
    "<br>\n",
    "*Author: Taufiq Rashid*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import itertools\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "#\n",
    "import numpy as np\n",
    "import shapely\n",
    "from shapely.geometry import shape, Point\n",
    "from shapely.geometry import mapping, Polygon\n",
    "# import cartopy\n",
    "import geojson\n",
    "import fiona\n",
    "import gdal\n",
    "import h5py\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "# import ogr, gdal\n",
    "from glob import glob\n",
    "\n",
    "import requests\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import collections\n",
    "\n",
    "import descarteslabs as dl\n",
    "from descarteslabs.vectors import FeatureCollection\n",
    "\n",
    "print (sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/data/phase_i/pavement/la_city/naip_imagery/'\n",
    "\n",
    "bands=['red','green','blue','nir']; suffix='RGBNA'  # S2, Lx\n",
    "resolution=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and acquire NAIP imagery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shape(place_shapefile):\n",
    "    c = fiona.open(place_shapefile)\n",
    "    pol = c.next()\n",
    "    shape = {}\n",
    "    shape['type'] = pol['type']\n",
    "    shape['properties'] = pol['properties']\n",
    "    shape['geometry'] = {}\n",
    "    shape['geometry']['type'] = 'Polygon'  # pol['geometry']['type']\n",
    "    shape['geometry']['coordinates'] = [[]]\n",
    "    # if MultiPolygon (e.g., city='kampala')\n",
    "    if (len(pol['geometry']['coordinates'])>1):\n",
    "        # identify largest single polygon\n",
    "#         print (\"MultiPolygon\", len(pol['geometry']['coordinates']))\n",
    "        p_argmax = 0 \n",
    "        pn_max = 0\n",
    "        for p in range(len(pol['geometry']['coordinates'])):\n",
    "            pn = len(pol['geometry']['coordinates'][p][0])\n",
    "            if pn>pn_max:\n",
    "                p_argmax = p\n",
    "                pn_max = pn\n",
    "#             print (p, pn, p_argmax, pn_max )\n",
    "        # make largest polygon the only polygon, move other polys to a backup variable \n",
    "        polygon = pol['geometry']['coordinates'][p_argmax]\n",
    "        \n",
    "        xmin =  180\n",
    "        xmax = -180\n",
    "        ymin =  90\n",
    "        ymax = -90\n",
    "        for x,y in polygon:\n",
    "            xmin = xmin if xmin < x else x\n",
    "            xmax = xmax if xmax > x else x\n",
    "            ymin = ymin if ymin < y else y\n",
    "            ymax = ymax if ymax > y else y\n",
    "            shape['geometry']['coordinates'][0].append([x,y])\n",
    "        shape['bbox'] = [xmin,ymin,xmax,ymax]\n",
    "\n",
    "        return shape\n",
    "    else:\n",
    "#         print ('simple polygon')\n",
    "        polygon = pol['geometry']['coordinates']\n",
    "       \n",
    "        xmin =  180\n",
    "        xmax = -180\n",
    "        ymin =  90\n",
    "        ymax = -90\n",
    "        for x,y in polygon[0]:\n",
    "            xmin = xmin if xmin < x else x\n",
    "            xmax = xmax if xmax > x else x\n",
    "            ymin = ymin if ymin < y else y\n",
    "            ymax = ymax if ymax > y else y\n",
    "            shape['geometry']['coordinates'][0].append([x,y])\n",
    "        shape['bbox'] = [xmin,ymin,xmax,ymax]\n",
    "    \n",
    "    return shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the imageries for the above shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the footprint csv to add 3 year albedos first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set your input file here\n",
    "output_filename = 'LAcity_pavement_re_buffered_5-2.csv'\n",
    "\n",
    "# Read the data to a Pandas Dataframe\n",
    "df_2 = pd.read_csv(output_filename, encoding='utf8')\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "addresses= df_2[['re_buffered_path','pavement_shapes','street_address', 'street_names', 'street_from','street_to','start_date', 'end_date', 'albedos']].apply(tuple, axis=1)\n",
    "addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buf_paths = []\n",
    "pavement_shapes = []\n",
    "st_adds = []\n",
    "st_names = []\n",
    "st_frms = []\n",
    "st_tos=[]\n",
    "start_dates = []\n",
    "end_dates = []\n",
    "albedos = []\n",
    "img_path = []\n",
    "scene_ids = []\n",
    "\n",
    "roof_id = 0\n",
    "\n",
    "format_str = '%m/%d/%Y' # The format\n",
    "\n",
    "# for shapefiles in paths:\n",
    "for Y, X in addresses.iteritems():\n",
    "    try:\n",
    "        buf_path = str(X[0])\n",
    "        pavement_shape = str(X[1])\n",
    "        st_add = str(X[2])\n",
    "        st_name = str(X[3])\n",
    "        st_frm = str(X[4])    \n",
    "        st_to = str(X[5])\n",
    "        start_date = str(X[6])\n",
    "    #         st_datetime_obj = datetime.datetime.strptime(start_date, format_str)\n",
    "    #         start_date = str(st_datetime_obj.date())\n",
    "        end_date = str(X[7])   \n",
    "    #         end_datetime_obj = datetime.datetime.strptime(end_date, format_str)\n",
    "    #         end_date = str(end_datetime_obj.date())\n",
    "        albedo = X[8]\n",
    "\n",
    "#         print(buf_path)\n",
    "        shape = load_shape(buf_path)\n",
    "    #         print(shape)\n",
    "\n",
    "#         print ('searching imageries for '+st_name)\n",
    "\n",
    "        product = u'usda:naip:rgbn:v1'\n",
    "\n",
    "\n",
    "        #  Search metadata given a spatio-temporal query\n",
    "        feature_collection = dl.metadata.search(products=[product], start_datetime=start_date, end_datetime=end_date,\n",
    "                                                 fields=['acquired'], sort_field='acquired',sort_order='asc',geom=shape['geometry'])\n",
    "    #     print(feature_collection)\n",
    "\n",
    "        naip_ids = [f['id'] for f in feature_collection['features']]\n",
    "        naip_ids.sort()\n",
    "    #         print (len(naip_ids))\n",
    "\n",
    "\n",
    "        if len(naip_ids) != 0:\n",
    "            roof_id = roof_id+1\n",
    "            naip_dates = [f['properties'] for f in feature_collection['features']]\n",
    "    #         print (naip_dates)\n",
    "            naip_dates = naip_dates[0]\n",
    "\n",
    "\n",
    "        img_id = - 1\n",
    "\n",
    "        for imageries in naip_ids:        \n",
    "    #         print ('downloading '+imageries)\n",
    "            ids = imageries[23:49]\n",
    "    #         print(ids)\n",
    "            continue_index = 0\n",
    "            img_id = img_id + 1\n",
    "            naip_band_file =  data_path+str(imageries[-6:-4])+'_naipV1_'+str(naip_dates)+'_street_'+str(roof_id).zfill(5)+'_'+'img_'+str(img_id).zfill(2)+'_'+str(resolution)+'m'\n",
    "    #         print (naip_band_file)\n",
    "            date = naip_band_file[71:81]\n",
    "#             print (date)\n",
    "            naip_band_file =  data_path+st_name+'_naipV1_'+date+'_st_'+str(roof_id).zfill(5)+'_'+'img_'+str(img_id).zfill(2)+'_'+str(resolution)+'m'\n",
    "#             print (naip_band_file)\n",
    "            naip = dl.raster.raster(\n",
    "                    imageries,\n",
    "                    bands=bands,\n",
    "                    data_type='UInt16',\n",
    "                    cutline=shape['geometry'],\n",
    "                    save=True,\n",
    "                    outfile_basename=naip_band_file)\n",
    "            pt = str(naip_band_file)+'.tif'\n",
    "            print(pt)\n",
    "            img_path.append(pt)\n",
    "            st_adds.append(st_add)\n",
    "            st_names.append(st_name)\n",
    "            st_frms.append(st_frm)\n",
    "            st_tos.append(st_to)\n",
    "            start_dates.append(start_date)\n",
    "            end_dates.append(end_date)\n",
    "            albedos.append(albedo)\n",
    "            buf_paths.append(buf_path)\n",
    "            pavement_shapes.append(pavement_shape)\n",
    "            scene_ids.append(ids)\n",
    "    except:\n",
    "        pass\n",
    "# store the results to a pandas library.\n",
    "df_path = pd.DataFrame({'img_path': img_path,'buffered_path': buf_paths,'pavement_shapes':pavement_shapes,'scene_ids':scene_ids,\n",
    "                        'street_address':st_adds, 'street_names':st_names, 'street_from': st_frms, \n",
    "                        'street_to': st_tos,'start_date': start_dates, 'end_date': end_dates, 'albedos': albedos})\n",
    "\n",
    "# Write the full results to csv using the pandas library. \n",
    "df_path.to_csv('LAcity_pavement_naip_5-2.csv',encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
