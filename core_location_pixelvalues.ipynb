{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Workflow: Get NAIP imageries from given addresses\n",
    "Purpose: Geocode addresses from an input csv file. Find matching polygons from Microsoft Building foorprint data using geocoded addresses. Use the shape of the polygons to download NAIP imageries for the rooftops.\n",
    "<br>\n",
    "*Date: 2019-02-08*\n",
    "<br>\n",
    "*Author: Taufiq Rashid*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import itertools\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "#\n",
    "import numpy as np\n",
    "import shapely\n",
    "from shapely.geometry import shape, Point\n",
    "from shapely.geometry import mapping, Polygon\n",
    "import cartopy\n",
    "import geojson\n",
    "import fiona\n",
    "import gdal\n",
    "import h5py\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import ogr, gdal\n",
    "\n",
    "import requests\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import collections\n",
    "\n",
    "import descarteslabs as dl\n",
    "\n",
    "ULU_REPO = os.environ[\"ULU_REPO\"]\n",
    "sys.path.append(ULU_REPO+'/utils')\n",
    "print sys.path\n",
    "\n",
    "import bronco\n",
    "import bronco_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = 'san_diego'  # setting the study area\n",
    "\n",
    "data_root='/data/phase_iii/NAIP/'\n",
    "data_path=data_root+place+'/'\n",
    "\n",
    "bands=['red','green','blue','nir','alpha']; suffix='RGBNA'  # S2, Lx\n",
    "resolution=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load GeoJSON file containing polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/phase_iii/microsoft_footprints/California.geojson') as f:\n",
    "    js = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supply the rooftop addresses and geocode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adapted from python batch geocoding.py by Shane Lynn\n",
    "logger = logging.getLogger(\"root\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create console handler\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "#------------------ CONFIGURATION -------------------------------\n",
    "\n",
    "# Set your Google API key here. \n",
    "API_KEY = 'AIzaSyDKrvutuGy1zFt3p4VLGA5Lq87AZYwmc2c'\n",
    "# Backoff time sets how many minutes to wait between google pings when your API limit is hit\n",
    "BACKOFF_TIME = 30\n",
    "# Set your output file name here.\n",
    "output_filename = 'geocded_addresses.csv'\n",
    "# Set your input file here\n",
    "input_filename = \"ground_truth.csv\"\n",
    "# Specify the column name in your input data that contains addresses here\n",
    "address_column_name = \"Address\"\n",
    "# Return Full Google Results? If True, full JSON results from Google are included in output\n",
    "RETURN_FULL_RESULTS = False\n",
    "\n",
    "#------------------ DATA LOADING --------------------------------\n",
    "\n",
    "# Read the data to a Pandas Dataframe\n",
    "data = pd.read_csv(input_filename, encoding='utf8')\n",
    "\n",
    "# Form a list of addresses for geocoding:\n",
    "# Make a big list of all of the addresses to be processed.\n",
    "addresses = data[address_column_name].tolist()\n",
    "\n",
    "#------------------\tFUNCTION DEFINITIONS ------------------------\n",
    "\n",
    "def get_google_results(address, api_key=API_KEY, return_full_response=False):\n",
    "\n",
    "    # Set up your Geocoding url\n",
    "    geocode_url = \"https://maps.googleapis.com/maps/api/geocode/json?address={}\".format(address) + \"&key={}\".format(api_key)\n",
    "        \n",
    "    # Ping google for the reuslts:\n",
    "    results = requests.get(geocode_url)\n",
    "    # Results will be in JSON format - convert to dict using requests functionality\n",
    "    results = results.json()\n",
    "    \n",
    "    # if there's no results or an error, return empty results.\n",
    "    if len(results['results']) == 0:\n",
    "        output = {\n",
    "            \"formatted_address\" : None,\n",
    "            \"latitude\": None,\n",
    "            \"longitude\": None,\n",
    "            \"accuracy\": None,\n",
    "            \"google_place_id\": None,\n",
    "            \"type\": None,\n",
    "            \"postcode\": None\n",
    "        }\n",
    "    else:    \n",
    "        answer = results['results'][0]\n",
    "        output = {\n",
    "            \"formatted_address\" : answer.get('formatted_address'),\n",
    "            \"latitude\": answer.get('geometry').get('location').get('lat'),\n",
    "            \"longitude\": answer.get('geometry').get('location').get('lng'),\n",
    "            \"accuracy\": answer.get('geometry').get('location_type'),\n",
    "            \"google_place_id\": answer.get(\"place_id\"),\n",
    "            \"type\": \",\".join(answer.get('types')),\n",
    "            \"postcode\": \",\".join([x['long_name'] for x in answer.get('address_components') \n",
    "                                  if 'postal_code' in x.get('types')])\n",
    "        }\n",
    "        \n",
    "    # Append some other details:    \n",
    "    output['input_string'] = address\n",
    "    output['number_of_results'] = len(results['results'])\n",
    "    output['status'] = results.get('status')\n",
    "    if return_full_response is True:\n",
    "        output['response'] = results\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Create a list to hold results\n",
    "results = []\n",
    "# Go through each address in turn\n",
    "for address in addresses:\n",
    "    # While the address geocoding is not finished:\n",
    "    geocoded = False\n",
    "    while geocoded is not True:\n",
    "        # Geocode the address with google\n",
    "        try:\n",
    "            geocode_result = get_google_results(address, API_KEY, return_full_response=RETURN_FULL_RESULTS)\n",
    "        except Exception as e:\n",
    "            logger.exception(e)\n",
    "            logger.error(\"Major error with {}\".format(address))\n",
    "            logger.error(\"Skipping!\")\n",
    "            geocoded = True\n",
    "            \n",
    "        # If we're over the API limit, backoff for a while and try again later.\n",
    "        if geocode_result['status'] == 'OVER_QUERY_LIMIT':\n",
    "            logger.info(\"Hit Query Limit! Backing off for a bit.\")\n",
    "            time.sleep(BACKOFF_TIME * 60) # sleep for 30 minutes\n",
    "            geocoded = False\n",
    "        else:\n",
    "            if geocode_result['status'] != 'OK':\n",
    "                logger.warning(\"Error geocoding {}: {}\".format(address, geocode_result['status']))\n",
    "            logger.debug(\"Geocoded: {}: {}\".format(address, geocode_result['status']))\n",
    "            results.append(geocode_result)           \n",
    "            geocoded = True\n",
    "\n",
    "    # Print status every 100 addresses\n",
    "    if len(results) % 100 == 0:\n",
    "    \tlogger.info(\"Completed {} of {} address\".format(len(results), len(addresses)))\n",
    "            \n",
    "    # Every 500 addresses, save progress to file(in case of a failure so you have something!)\n",
    "    if len(results) % 500 == 0:\n",
    "        pd.DataFrame(results).to_csv(\"{}_bak\".format(output_filename))\n",
    "\n",
    "# All done\n",
    "logger.info(\"Finished geocoding all addresses\")\n",
    "# Write the full results to csv using the pandas library.\n",
    "pd.DataFrame(results).to_csv(output_filename, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### store the geocoded addresses to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your input file here\n",
    "output_filename = \"geocded_addresses.csv\"\n",
    "\n",
    "# Read the data to a Pandas Dataframe\n",
    "df = pd.read_csv(output_filename, encoding='utf8')\n",
    "\n",
    "addresses= df[['longitude','latitude']].apply(tuple, axis=1)\n",
    "addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch processing for finding matching footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for Y, X in addresses.iteritems():\n",
    "    print 'Searching matching polygon for:', X[0],X[1]\n",
    "    # construct point based on lat/long returned by geocoder\n",
    "    point = Point(X[0],X[1])\n",
    "\n",
    "    # check each polygon to see if it contains the point\n",
    "    for feature in js['features']:\n",
    "        polygon = shape(feature['geometry'])\n",
    "        if polygon.contains(point):\n",
    "            print 'Found containing polygon:', feature\n",
    "\n",
    "            # Define a polygon feature geometry with one attribute\n",
    "            schema = {\n",
    "                'geometry': 'Polygon',\n",
    "                'properties': {'id': 'int'},\n",
    "            }\n",
    "\n",
    "            # Write a new Shapefile\n",
    "            with fiona.open('my_shp.shp', 'w', 'ESRI Shapefile', schema) as c:\n",
    "                ## If there are multiple geometries, put the \"for\" loop here\n",
    "                c.write({\n",
    "                    'geometry': mapping(polygon),\n",
    "                    'properties': {'id': 123},\n",
    "                })\n",
    "            #As soon as you find the matching polygon, break out of the loop\n",
    "            break\n",
    "            \n",
    "shape = bronco_candidates.load_shape('my_shp.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and acquire NAIP imagery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = u'762932f1db2b68d82f08b527ffe5a32d949dc8ec:usda:naip:rgbn:ca'\n",
    "\n",
    "#  Search metadata given a spatio-temporal query\n",
    "feature_collection = dl.metadata.search(product=[product], start_time='2009-01-01', end_time='2009-12-31',\n",
    "                                        limit=10, geom=shape['geometry'])\n",
    "naip_ids = [f['id'] for f in feature_collection['features']]\n",
    "naip_ids.sort()\n",
    "print len(naip_ids), naip_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the imageries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull from api and save to file \n",
    "naip_dict = {}\n",
    "naip_dict['A'] = [u'762932f1db2b68d82f08b527ffe5a32d949dc8ec:usda:naip:rgbn:ca:Brdf_006_034_092306_2136_RGBNN00L2_SD_4_0']\n",
    "\n",
    "continue_index = 0\n",
    "\n",
    "for naip_suffix, naip_imgs in naip_dict.iteritems():\n",
    "    print naip_suffix, naip_imgs\n",
    "    continue_index = 0\n",
    "    naip_band_file =  data_path+place+'_naip_'+naip_suffix+'_0623'+'_'+str(resolution)+'m'\n",
    "    print naip_band_file\n",
    "    naip = dl.raster.raster(\n",
    "            naip_imgs,\n",
    "            bands=bands,\n",
    "            data_type='UInt16',\n",
    "            cutline=shape['geometry'],\n",
    "            save=True,\n",
    "            outfile_basename=naip_band_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
